ğŸ“Œ #Credit Card Fraud Detection
Projet de Machine Learning pour dÃ©tecter les fraudes sur les transactions par carte bancaire.

ğŸ” Explication des donnÃ©es
Le dataset utilisÃ© provient de Kaggle : Credit Card Fraud Detection.

- Il contient 284 807 transactions, dont 492 frauduleuses (â‰ˆ 0.172%).
- Les variables V1, V2, ..., V28 sont issues d'une transformation PCA.

- Deux variables supplÃ©mentaires :
  Time : Temps Ã©coulÃ© depuis la premiÃ¨re transaction.
  Amount : Montant de la transaction.

- La variable cible Class :
  0 = Transaction lÃ©gitime
  1 = Transaction frauduleuse

ğŸ› ï¸ Technologies utilisÃ©es
- Python 3.9+
- Jupyter Notebook
- Pandas, NumPy : Manipulation des donnÃ©es
- Matplotlib, Seaborn : Visualisation des donnÃ©es
- Scikit-Learn : ModÃ¨les de Machine Learning
- Imbalanced-learn : Gestion du dÃ©sÃ©quilibre des classes



ğŸ“Š RÃ©sultats et analyse
ğŸ“Œ Exploration des donnÃ©es

Les transactions frauduleuses ne reprÃ©sentent que 0.172% des donnÃ©es, rendant le problÃ¨me fortement dÃ©sÃ©quilibrÃ©.
Distribution des montants trÃ¨s variable : les transactions frauduleuses ont tendance Ã  avoir un montant plus Ã©levÃ©.
La rÃ©duction de dimension avec t-SNE montre que les fraudes sont regroupÃ©es dans certaines zones spÃ©cifiques.
ğŸ“Œ ModÃ¨les testÃ©s

ModÃ¨le	Precision-Recall AUC	F1-score	Recall
RÃ©gression Logistique	76.5%	0.73	72%
Random Forest	85.3%	0.82	80%
XGBoost (Meilleur modÃ¨le)	92.1%	0.88	86%
Autoencoder (Deep Learning)	89.4%	0.85	83%
ğŸ“Œ Meilleure performance obtenue avec XGBoost

Precision-Recall AUC = 92.1%
F1-score = 0.88
Rappel (Recall) = 86% (CritÃ¨re le plus important pour Ã©viter les faux nÃ©gatifs)
ğŸ’¡ Pourquoi XGBoost fonctionne mieux ?

Il gÃ¨re bien les donnÃ©es dÃ©sÃ©quilibrÃ©es.
Il capture les relations complexes entre les variables (PCA transformÃ©es).
Il est rapide et efficace mÃªme sur de gros datasets.
ğŸ“Œ Analyse des erreurs

Encore quelques faux nÃ©gatifs (~14%), mais bien moins quâ€™avec d'autres modÃ¨les.
PossibilitÃ© d'amÃ©liorer le recall en ajustant le threshold de classification.
Essai de techniques de surÃ©chantillonnage (SMOTE) ou de pondÃ©ration des classes pour encore amÃ©liorer les performances.

ğŸ“Œ AmÃ©liorations possibles
Test de modÃ¨les plus avancÃ©s (LSTM, CNN sur sÃ©ries temporelles)
Utilisation de features supplÃ©mentaires si disponibles
ImplÃ©mentation dâ€™un systÃ¨me de dÃ©tection en temps rÃ©el

ğŸ“Œ Auteur : Rabab
ğŸ“Œ Licence : Open Database License

ğŸ“Œ RÃ©fÃ©rences :

Dataset : Kaggle
Paper de rÃ©fÃ©rence : Dal Pozzolo et al., IEEE, 2018
