# Credit Card Fraud Detection
Projet de Machine Learning pour dÃ©tecter les fraudes sur les transactions par carte bancaire.

## ğŸ” Explication des donnÃ©es
Le dataset utilisÃ© provient de Kaggle : **Credit Card Fraud Detection**.

- Il contient **284 807 transactions**, dont **492 frauduleuses** (â‰ˆ 0.172%).
- Les variables **V1, V2, ..., V28** sont issues d'une transformation PCA.
- Deux variables supplÃ©mentaires :
  - **Time** : Temps Ã©coulÃ© depuis la premiÃ¨re transaction.
  - **Amount** : Montant de la transaction.
- La variable cible **Class** :
  - **0** = Transaction lÃ©gitime
  - **1** = Transaction frauduleuse

## ğŸ› ï¸ Technologies utilisÃ©es
- Python 3.9+
- Jupyter Notebook
- Pandas, NumPy : Manipulation des donnÃ©es
- Matplotlib, Seaborn : Visualisation des donnÃ©es
- Scikit-Learn : ModÃ¨les de Machine Learning
- Imbalanced-learn : Gestion du dÃ©sÃ©quilibre des classes

## ğŸ“Š RÃ©sultats et analyse
### ğŸ“€ Exploration des donnÃ©es
- Les transactions frauduleuses ne reprÃ©sentent que **0.172%** des donnÃ©es, rendant le problÃ¨me fortement dÃ©sÃ©quilibrÃ©.
- Distribution des montants trÃ¨s variable : les transactions frauduleuses ont tendance Ã  avoir un montant plus Ã©levÃ©.
- La rÃ©duction de dimension avec **t-SNE** montre que les fraudes sont regroupÃ©es dans certaines zones spÃ©cifiques.

### ğŸ‘‰ ModÃ¨les testÃ©s
| ModÃ¨le                | Precision-Recall AUC | F1-score | Recall |
|------------------------|----------------------|----------|--------|
| RÃ©gression Logistique | 76.5%                | 0.73     | 72%    |
| Random Forest         | 85.3%                | 0.82     | 80%    |
| **XGBoost** (Meilleur) | **92.1%**            | **0.88** | **86%** |
| Autoencoder (Deep Learning) | 89.4% | 0.85 | 83% |

### ğŸ“Œ Meilleure performance obtenue avec **XGBoost**
- **Precision-Recall AUC** = 92.1%
- **F1-score** = 0.88
- **Recall** = 86% (CritÃ¨re le plus important pour Ã©viter les faux nÃ©gatifs)

### ğŸ’¡ Pourquoi **XGBoost** fonctionne mieux ?
- Il gÃ¨re bien les **donnÃ©es dÃ©sÃ©quilibrÃ©es**.
- Il capture les **relations complexes** entre les variables (PCA transformÃ©es).
- Il est **rapide et efficace** mÃªme sur de gros datasets.

### ğŸ” Analyse des erreurs
- Encore quelques **faux nÃ©gatifs (~14%)**, mais bien moins quâ€™avec d'autres modÃ¨les.
- PossibilitÃ© d'amÃ©liorer le recall en ajustant le **threshold de classification**.
- Essai de techniques de **surÃ©chantillonnage (SMOTE)** ou de **pondÃ©ration des classes** pour encore amÃ©liorer les performances.

## ğŸ’ª AmÃ©liorations possibles
- Test de modÃ¨les plus avancÃ©s (**LSTM, CNN sur sÃ©ries temporelles**).
- Utilisation de **features supplÃ©mentaires** si disponibles.
- ImplÃ©mentation dâ€™un **systÃ¨me de dÃ©tection en temps rÃ©el**.

---
## ğŸ‘¤ Auteur : **Rabab**
## ğŸ“ Licence : **Open Database License**
## ğŸ“š RÃ©fÃ©rences
- **Dataset** : [Kaggle - Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud)
- **Paper de rÃ©fÃ©rence** : Dal Pozzolo et al., IEEE, 2018

